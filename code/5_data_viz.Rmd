### Title: 2023_10_23_LSG_polyseq Analysis
### Author: Kate Johnson
### Date: 11/01/23
### Add'tl Notes:

# setup
libraries
```{r}
# all-purpose data analysis tools
library(tidyverse)
# ggplot extension
library(cowplot)
#correlation plots
library(corrplot)
# easier string formatting
library(glue)
# filepath manipulation
library(fs)

# edgeR and limma for DE analysis
library(edgeR)
library(limma)

# for reading/writing .gct files
#library(cmapR)

# for working with matrices (especially sparse ones)
library(Matrix)

#complex heatmap
library(ComplexHeatmap)
library(circlize) #for colorRamp2 color scaling
```
directories
```{r}
wd = getwd()
# For accessing shared data on server
shared_dir = "/Volumes/nchevrier/katej/projects/polysome-seq/2023_10_23_LSG_polyseq/bcbio"
# For reading in counts/metadata
input_dir = path(wd, "../input/data/2_formatted_data")
# For saving plots  
output_dir = path(wd, "../output/2023_10_30-LSG")
```

sources
```{r}

```

#complex heatmap plot fxn
move to plotting functions!
```{r}
do_plot = function(file_name, w, h, p) {
  pdf(file=path(output_dir, file_name), width = w, height = h)
      draw(p)
      dev.off()
}
```

# Read in Data
```{r, warnings =F}

#counts
counts = read_csv(path(input_dir, "20231101_LSG_polysome_counts.csv")) 
#rename gene column
colnames(counts)[1] = "gene"
# format matrix to be ready for de analysis
genes <- counts$gene
counts$gene <- NULL
rownames(counts) <- genes

#meta        
metadata = read_csv(path(input_dir, "20231101_LSG_polysome_metadata.csv")) %>%
           #drop unused first col
           select(-1)
```
# QC

complexity
- ratio of unique molecules to the number of reads
- unique molecular identifiers (UMIs) allow us to collapse molecules that we read multiple times
    - A higher complexity means more information for the amount of reads we have
- calculate complexity by comparing the UMI counts (`counts`) to the uncollapsed read counts 
- should be ~0.6, so a large deviation below that might be cause for concern
- raw read counts are called "tagcounts-dupes" by bcbio

```{r}
## make a table of total counts per sample
counts_summary = enframe(colSums(counts), name='Name', value='counts') %>%
    left_join(metadata)

# read in raw read counts
counts_dir = path(shared_dir, "final/2023-10-31_bcbio")

# read matrix
reads = readMM(path(counts_dir, 'tagcounts-dupes.mtx'))

# add rownames and colnames
rownames(reads) = read_lines(path(counts_dir, 'tagcounts-dupes.mtx.rownames'))
colnames(reads) = read_lines(path(counts_dir, 'tagcounts-dupes.mtx.colnames'))

## calculate counts for reads and add to summary table
# get read counts
reads = enframe(colSums(reads), name = 'sample', value = 'read_counts') %>%
        rename_all(~str_to_title(.))

# join to counts
counts_summary = left_join(counts_summary, reads)

#plot
p<-counts_summary %>%
    mutate(complexity = counts / Read_counts) %>%
    ggplot(aes(str_c(pool, "_", replicate),
               complexity, fill=pool)) + 
        geom_col() + 
        facet_grid(. ~ treatment) + 
        labs(x = "Polysome Fraction", title = "Sample Complexity (UMIs / Uncollapsed Read Counts)") +
        #guides(fill = 'none') + 
        theme(axis.text.x = element_text(angle = 45, hjust = .5, vjust = .5, size = rel(0.5)),
              plot.title = element_text(hjust = 0.5))

#save_plot
save_plot(path(output_dir, "QC_plots/sample_complexity_replicate_barplot.pdf"),p)

```

counts per sample
```{r}
p<-ggplot(counts_summary, aes(str_c(pool, '_', replicate), 
                   counts, fill=pool)) + 
    geom_col() + 
    facet_grid(treatment ~ .) + 
    #scale_y_log10() +
    #guides(fill = 'none') + 
    xlab('Polysome Fraction') +
    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5))

save_plot(path(output_dir, "QC_plots/counts_per_sample.pdf"), p, dpi = 90)
```

replicate correlation
```{r}
# commenting out for now bc not particularly informative
#pairwise correlations between samples for each treatment
#for(treatment in unique(metadata$treatment)){
#    suppressWarnings(
#        gplots::heatmap.2(cor(counts[, metadata$treatment == treatment]),
#                          trace = 'none', Rowv=F, Colv=F, 
#                         col=viridis::viridis(75),
#                          margins = c(10, 10))
#    )
#}

# table of all pairwise correlations < 0.9
# get all pairwise correlations
cormelt = as_tibble(reshape2::melt(cor(counts)))
colnames(cormelt) = c('s1', 's2', 'cor')

filt_cormelt = cormelt %>%
    # extract pieces of name for sample 1
    extract(s1, c('treatment', 'replicate1', 'pool'), '(.*)_(.*)_(.*)') %>%
    # extract pieces of name for sample 2
    extract(s2, c('treatment2', 'replicate2', 'pool2'), '(.*)_(.*)_(.*)') %>%
    # only keep samples where treatment and pool match
    # replicate1 < replicate2 removes duplicate comparisons
    filter(treatment == treatment2, pool == pool2, replicate1 < replicate2) %>%
    # comparison column makes for easier reading
    mutate(comparison = str_c(replicate1, '-', replicate2)) %>%
    # remove extraneous columns
    select(-treatment2, -pool2, -replicate1, -replicate2) #%>%
    # all correlations are above 0.9 so keep everything for now
    # filter(cor < .9)


p<-ggplot(filt_cormelt,
       aes(x = treatment, y = pool, fill = cor)) +
       geom_tile() +
       geom_text(aes(label = round(cor,3)), 
                  hjust = 0.5, vjust = 0.5) +
       facet_wrap(~comparison)
  
#save plot 
save_plot(path(output_dir, "QC_plots/replicate_correlation.pdf"),p, dpi = 90)
```


# Data Normalization
```{r}
#set cpm thresholds (keep low to start)
cpm_threshold = 10
cpm_needed = 2

groups <- factor(str_c(metadata$treatment, '_', metadata$pool))
dge = DGEList(counts = counts, group = groups)
dge_norm = calcNormFactors(dge)
isexpr = rowSums(cpm(dge_norm) > cpm_threshold) >= cpm_needed

dge_norm_fltd = dge_norm[isexpr, ]

cpm = cpm(dge_norm_fltd) #dropped to ~8,000 genes
cpm_all = cpm(dge_norm)

# reorder cols so its easier to open in morpheus
# use metadata to help establish order
metadata = metadata %>%
           arrange(treatment, pool, replicate)
cpm = cpm[,metadata$Name]

#save cpm heatmaps for plotting in morpheus
write.csv(as.matrix(cpm), path(output_dir, "cpm_tables/20231101_LSG_cpmTable_filt.csv"))
write.csv(as.matrix(cpm_all), path(output_dir, "cpm_tables/20231101_LSG_cpmTable_all.csv"))

```

PCA
```{r}
# run pca
pca = prcomp(t(cpm), center=T, scale=T)
# combine pca results with metadata for easy plotting
pca_res = bind_cols(metadata, as_tibble(pca$x))

# plot

# color by treatment
p1<-ggplot(pca_res, aes(PC1, PC2, color=treatment)) + 
    geom_point(size=2) +
    scale_color_manual(values = c("grey", "peachpuff1","#F68064"))

# color by pool
p2<-ggplot(pca_res, aes(PC1, PC2, color=pool)) + 
    geom_point(size=2) +
    scale_color_manual(values = c("#68C3A5", "#B9CEE6", "#8C9FCA","#707FA1"))

# color by replicate
p3<-ggplot(pca_res, aes(PC1, PC2, color=replicate)) + 
    geom_point(size=2)

# save plots
save_plot(path(output_dir, "QC_plots/PCA/PCA_by_treatment.pdf"),p1,dpi=90)
save_plot(path(output_dir, "QC_plots/PCA/PCA_by_pool.pdf"),p2,dpi=90)
save_plot(path(output_dir, "QC_plots/PCA/PCA_by_replicate.pdf"),p3,dpi=90)
```


# DE analysis

The general steps for modeling are: 
1. Filter cpm and metadata based on the tissue at hand
2. Make a design matrix specifying the experimental condition of each sample 
3. Run `voom()` to transform and prepare data
4. Run initial `lmFit()` to fit data
5. Setup contrasts between groups for tests you want to run
    1. List contrasts
    2. Make contrast matrix
6. Run `contrast.fit()` to fit contrasts
7. Run `eBayes` to estimate statistic results
8. Gather results into useful tables

```{r}
# FILTER COUNTS & METADATA TO DROP BAD REPLICATE----
# LSGh6 input rep1 has low counts and clusters poorly -- so we will drop it

#set cpm thresholds (keep low to start)
cpm_threshold = 10
cpm_needed = 2

counts_filt = counts %>%
              select(-LSG6h_Rep1_Input)
meta_filt = metadata %>% filter(Name %in% colnames(counts_filt))
rownames(counts_filt) = rownames(counts)

# check that col order of counts_filt and row order of meta_filt match
sum(colnames(counts_filt) == meta_filt$Name) #sum is 35 (same as so looks like all match)

# re-do dge list object creation
groups <- factor(str_c(meta_filt$treatment, '_', meta_filt$pool))
dge = DGEList(counts = counts_filt, group = groups)
dge_norm = calcNormFactors(dge)
isexpr = rowSums(cpm(dge_norm) > cpm_threshold) >= cpm_needed
dge_norm_fltd = dge_norm[isexpr, ]


# DESIGN MATRIX----
# create factor with all conditions in experiment
f <- factor(groups, levels=unique(groups))

# build a design matrix for modeling with limma voom and indicating condition for each sample
design <- model.matrix(~0 + f)

# renames column names in the design (remove extra "f" at beginning of each group name)
colnames(design) <- sub("f", "", colnames(design))
rownames(design) <- colnames(counts_filt)

##LIMMA VOOM 

# limma voom transforms count data to log2-counts per million (log2-cpm) with associated weights
# estimate the mean-variance relationship and use this to compute appropriate observational-level weights.
# The data are then ready for linear modeling.
y <- voom(dge_norm_fltd, design, plot=T)

# fit linear model for each gene given a series of arrays
fit <- lmFit(y, design)

##CONTRAST MATRIX----
# each contrast for DE will be one pool in treated - control (ie. LSG2h_input - Control_input)
# 1. get all treatments that arent control
# 2. make an equivalent list with the same pools in control
# 3. subtract 1 - 2
all_cond = levels(groups)[!grepl("Control", (levels(groups)))]
conts = gsub(".*_", "Control_", all_cond)
contrasts_list = str_c(all_cond, " - ", conts)

contrast.matrix <- makeContrasts(contrasts = contrasts_list, levels = design)

#do some renaming of scores to facilitate pivoting later on and make our lives easier...
contrast.matrix = contrast.matrix %>%
                  as.data.frame %>% #convert to df for now for manipulation
                  rename_with(., ~gsub(" - Control.*", "", .)) %>%
                  as.matrix()

fit.cont <- contrasts.fit(fit, contrast.matrix)

e.fit <- eBayes(fit.cont)

#first bind together all LFC lists for all genes from ea. contrast
log2FC.all = as.data.frame(map_dfc(1:length(colnames(e.fit$contrasts)),
                             function(coef) topTable(e.fit, coef=coef, number=Inf,
                                                     sort.by='none')$logFC)) %>%
      data.frame()

adj_p = as.data.frame(map_dfc(1:length(colnames(e.fit$contrasts)),
                                    function(coef) topTable(e.fit, coef=coef, number=Inf,
                                                            sort.by='none')$adj.P.Val))

rownames(log2FC.all) = rownames(adj_p) = make.unique(rownames(dge_norm_fltd), sep = ".")
colnames(log2FC.all) = colnames(adj_p) = colnames(e.fit$contrasts)

#turn log2FC.all.binary into matrix of -1,0,1
FDR_thresh = 0.01
log2FC.all.binary = adj_p %>%
              mutate_all(~ifelse(. < FDR_thresh, 1, 0))

#filter LFC matrix accordingly
log2FC.all.binary[(log2FC.all < 0) == T] = -1 * log2FC.all.binary[(log2FC.all < 0) == T]
names = rownames(log2FC.all.binary)
log2FC.all.binary = log2FC.all.binary %>%
               data.frame()

DE_log2FC.all = log2FC.all[rowSums(log2FC.all.binary != 0) > 0,] %>%
          data.frame()
rownames(DE_log2FC.all) = rownames(log2FC.all)[rowSums(log2FC.all.binary != 0) > 0]

#filter DE matrix based on LFC thresh
LFC_thresh = 1
DE_LFC_thresh = DE_log2FC.all %>%
          filter_all(any_vars(abs(.) > LFC_thresh))

#write csvs of DEGs and all log2FC
write.csv(as.matrix(DE_LFC_thresh), path(output_dir, "DE_analysis/filtered/FDR0.1_LFC1/20231101_filtered_FDR0.1_LFC1_DE-genes-lfcTable.csv"))

```

# Translation Efficiency ----
First plot % of total transcripts in each pool (take cpm in each pool and divide by input cpm)
Use only DE genes 
We will use this to help assess different methods of calculating TE
- First use FDR < 0.01 |LFC| > 0 (~7304 genes)
```{r}

#bind rownames as its own column ('gene') to make sure gene names dont get lost during manipulation
percent_transcript = cbind(gene = rownames(DE_log2FC.all), cpm[rownames(DE_log2FC.all),]) %>%
                     #make df for easier manipulation
                     data.frame() %>%
                     #pivot longer so we can average over replicates
                     pivot_longer(cols = -gene, names_to ="Name", values_to = "cpm") %>%
                     #split "Name" column into relevant info
                     separate(Name, into = c("Treatment", "Rep", "Pool"), sep="_") %>%
                     #pivot wider to get reps in separate cols
                     pivot_wider(names_from = "Rep", values_from = "cpm") %>%
                     #make cpm numeric (preserving NA values)
                     mutate_at(.vars = vars(Rep1:Rep3), ~ifelse(!(is.na(.)), as.numeric(.), .)) %>%
                     #calculate average
                        #struggling to get rowwise operations working correctly
                        #so sticking to a more manual calc for now
                     mutate(Avg_cpm = (Rep1 + Rep2 + Rep3) / 3) %>%
                     #drop raw info after spot checking averages
                     select(-contains("Rep"))
                    
#store inputs separately
inputs = percent_transcript %>%
         filter(Pool == "Input") %>%
         #drop Treatment column to avoid duplicates during merge
         select(-Pool) %>%
         rename("Avg_input_cpm" = Avg_cpm)

#bind inputs back to other pools and divide by inputs to get %
percent_total = percent_transcript %>%
                     #filter out inputs
                     filter(Pool != "Input") %>%
                     # bind inputs
                     merge(inputs, by = c("gene", "Treatment")) %>%
                     #calculate % of input 
                     # because we have normalized some ratios will be > 100%
                     mutate(percent_of_total = Avg_cpm/Avg_input_cpm * 100)

#format df for complex heatmap
df = percent_total %>%
     select(-contains("Avg")) %>%
     pivot_wider(names_from = c("Treatment", "Pool"),
                 values_from = "percent_of_total")

#prepare annotations
top_annot = data.frame(Name = colnames(df)[-1]) %>%
            separate(Name, into = c("Treatment", "Pool"), sep ="_")
rownames(top_annot) = colnames(df)[-1]

rwnmes = df$gene
H = df %>%
    select(-gene) %>%
    as.matrix()
rownames(H) = rwnmes
  
p<-Heatmap(H,
        column_title = "% of Total mRNA in Pool",
        name = "Avg_pool_cpm / Avg_input_cpm",
        show_row_names = F,
        show_column_names=F,
        #cluster_rows =T,
        cluster_columns = F,
        top_annotation = HeatmapAnnotation(df = top_annot,
                         col = list(Treatment = c(Control = "grey",
                                                   LSG2h = "#F89F7C",
                                                  LSG6h = "#F68064"),
                                   Pool = c("Pool1" = "#68C3A5", 
                                            "Pool2" ="#539C84",
                                            "Pool3" ="#3E7563")),
                          border = T,
                          show_legend = F,
                          annotation_name_gp = gpar(fontsize = 8)),
        column_split = top_annot$Treatment,
        column_gap = unit(2, "mm"),
        row_km = 20,
        row_gap = unit(0, "mm"),
        col = colorRamp2(c(0, 100, 200), c("white", "#8C9FCA", "darkblue"))
        )

#save plot
do_plot( "TE_analysis/Percent-mRNA-in-pool/FDR0.01/Pool-cpm_div_input-cpm.pdf", 8, 6, p)

#write csv
write.csv(as.matrix(H), path(output_dir, "TE_analysis/Percent-mRNA-in-pool/FDR0.01/Pool_cpm-div-Input_cpm.csv"))


#same plot but only 3,000 highly regulated transcripts
```

